{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capítulo 14 - Generative Adversarial Networks\n",
    "\n",
    "En este capítulo introducimos las redes conocidas como Generative Adversarial Networks (GAN), que están generando un gran intereés al ser las responsables en gran medida de las *deepfakes*. Estoy seguro de que resultará interesante para el lector o lectroa acabar el libro con este tema tan actual. Aprovecharemos la explicación de las GAN para introducir ootros tipos de capas de redes no vistas hasta ahora, y alternativas de programación de la API de Keras hasta ahora en el entorno TensorFlow 2.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.1. Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1.1. Motivación por las GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1.2. Arquitectura de las GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1.3. Proceso de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.2. Programando una GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.1. Preparación del entrono y la descarga de datos\n",
    "\n",
    "Pasamos a codificar nuestro ejemplo, comenzando por preparar el entorno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.1\n"
     ]
    }
   ],
   "source": [
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante asegurarse de que estamos usando TensorFlow 2. Además, también es relevante comprobar que tenemos asignada una GPU, pues ahora la etapa de entrenamiento ya es computacionalmente costosa y se requiere *hardware* acelerador para asegurar que se ejecuta en un tiempo razonable. Podemos hacerlo ejecutando el comando *bash* de Linux `nvidia-smi`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb  5 23:10:35 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 546.33                 Driver Version: 546.33       CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1080      WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   44C    P8              14W / 198W |   2810MiB /  8192MiB |      8%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1880    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      4812    C+G   ...ir\\CORSAIR iCUE 4 Software\\iCUE.exe    N/A      |\n",
      "|    0   N/A  N/A      6080    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A      9944    C+G   ...aam7r\\AcrobatNotificationClient.exe    N/A      |\n",
      "|    0   N/A  N/A     10064    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe    N/A      |\n",
      "|    0   N/A  N/A     11048    C+G   ...l\\Microsoft\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A     11408    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     11732    C+G   ...ejd91yc\\AdobeNotificationClient.exe    N/A      |\n",
      "|    0   N/A  N/A     14032    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     14216    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14544    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     15888    C+G   ...on\\121.0.2277.98\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     16016    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     18288    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     21516    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     22304    C+G   ...b3d8bbwe\\Microsoft.Media.Player.exe    N/A      |\n",
      "|    0   N/A  N/A     22468    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     22524    C+G   ...on\\wallpaper_engine\\wallpaper32.exe    N/A      |\n",
      "|    0   N/A  N/A     23048    C+G   ...\\iCloud\\WebView2\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     24964    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
      "|    0   N/A  N/A     25632    C+G   ...m Files\\Mozilla Firefox\\firefox.exe    N/A      |\n",
      "|    0   N/A  N/A     27044    C+G   ...\\Docker\\frontend\\Docker Desktop.exe    N/A      |\n",
      "|    0   N/A  N/A     27260    C+G   ...tionsPlus\\logioptionsplus_agent.exe    N/A      |\n",
      "|    0   N/A  N/A     27604    C+G   ...l\\Microsoft\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A     29060    C+G   ...5.0_x64__cv1g1gvanyjgm\\WhatsApp.exe    N/A      |\n",
      "|    0   N/A  N/A     29260    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A     32568    C+G   ...35.0_x64__zpdnekdrzrea0\\Spotify.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en este caso tenemos asignada una P100, ¡no está mal! A continuación, podemos importar todos los paquetes necesarios para ejecutar el modelo propuesto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as pyplot\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ya podemos descargar las imágenes de conjunto de datos MNIST de dígitos escritos a mano, que serán las imágenes que consideremos reales para nuestro ejemplo. Podemos hacerlo directamente desde `keras.datasets` y preparar las imágenes para ser usadas por las redes con el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso solo nos interesan las imágenes y, por tanto, no descargamos ni las *labels* ni los datos de prueba (usaremos `_` para indicar que no necesitamos estos datos y que pueden ser desechables).\n",
    "\n",
    "Podemos ver en el código que estas imágenes se han normalizado en el rango [-1, 1] para poder usar como función de activación en la capa final del Generador la funcion `tanh`, como veremos a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = (train_images - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barajamos y preparamos los datos en lotes con el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.2. Creación de los modelos\n",
    "\n",
    "A continuación, ya podemos pasar a crear las redes neuronales que actuarán de Generador y Discriminador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.2.2.1. Generador\n",
    "\n",
    "Siguiendo el esquema que habíamos descrito, el Generador recibe como entrada ruido, que puede obtener por ejemplo con `tf.random.normal`. De este ruido debe crear una imagen de 28 x 28 píxeles.\n",
    "\n",
    "El generador que obtiene una imagen de estas características a partir del vector de ruido que hemos indicado podría ser como el programado en el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Reshape, Conv2DTranspose, BatchNormalization, LeakyReLU\n",
    "\n",
    "def make_generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(7*7*256, use_bias=False, input_shape=(100)))\n",
    "\n",
    "    model.add(Reshape(7,7,256))\n",
    "\n",
    "    model.add(Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    model.add(Conv2DTranspose(64, (5, 5), strides=(1, 1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', activation='tanh'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.2.2.2. Discriminador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.3. Funciones de pérdida y optimizadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.3. Enrutamiento de la API de bajo nivel de TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.1. API de bajo nivel de TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.2. Algoritmo de aprendizaje a bajo nivel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.3. Entrenamiento de las redes GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.4. Mejora del rendimiento computacional con decoradores de funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.5. Evaluación de los resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
