{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capítulo 14 - Generative Adversarial Networks\n",
    "\n",
    "En este capítulo introducimos las redes conocidas como Generative Adversarial Networks (GAN), que están generando un gran intereés al ser las responsables en gran medida de las *deepfakes*. Estoy seguro de que resultará interesante para el lector o lectroa acabar el libro con este tema tan actual. Aprovecharemos la explicación de las GAN para introducir ootros tipos de capas de redes no vistas hasta ahora, y alternativas de programación de la API de Keras hasta ahora en el entorno TensorFlow 2.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.1. Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1.1. Motivación por las GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1.2. Arquitectura de las GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1.3. Proceso de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.2. Programando una GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.1. Preparación del entrono y la descarga de datos\n",
    "\n",
    "Pasamos a codificar nuestro ejemplo, comenzando por preparar el entorno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "['/device:CPU:0', '/device:GPU:0']\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante asegurarse de que estamos usando TensorFlow 2. Además, también es relevante comprobar que tenemos asignada una GPU, pues ahora la etapa de entrenamiento ya es computacionalmente costosa y se requiere *hardware* acelerador para asegurar que se ejecuta en un tiempo razonable. Podemos hacerlo ejecutando el comando *bash* de Linux `nvidia-smi`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb  8 20:22:50 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 551.23                 Driver Version: 551.23         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1080      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| 50%   69C    P0            173W /  198W |    3596MiB /   8192MiB |     92%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      4052    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A      7216    C+G   ...on\\wallpaper_engine\\wallpaper32.exe      N/A      |\n",
      "|    0   N/A  N/A      8432    C+G   ...\\iCloud\\WebView2\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A      8824    C+G   ...tionsPlus\\logioptionsplus_agent.exe      N/A      |\n",
      "|    0   N/A  N/A      9032    C+G   ...\\Docker\\frontend\\Docker Desktop.exe      N/A      |\n",
      "|    0   N/A  N/A     11004    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     11508    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     11892    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     13212    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A     14108    C+G   ...5.0_x64__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
      "|    0   N/A  N/A     14604    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     16104    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     16388    C+G   ...ir\\CORSAIR iCUE 4 Software\\iCUE.exe      N/A      |\n",
      "|    0   N/A  N/A     16412    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     17820    C+G   ...Programs\\Python\\Python39\\python.exe      N/A      |\n",
      "|    0   N/A  N/A     17888    C+G   ...l\\Microsoft\\Teams\\current\\Teams.exe      N/A      |\n",
      "|    0   N/A  N/A     18004    C+G   ...n\\121.0.2277.106\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     19936    C+G   ...aam7r\\AcrobatNotificationClient.exe      N/A      |\n",
      "|    0   N/A  N/A     21056    C+G   ...b3d8bbwe\\Microsoft.Media.Player.exe      N/A      |\n",
      "|    0   N/A  N/A     22688    C+G   ...l\\Microsoft\\Teams\\current\\Teams.exe      N/A      |\n",
      "|    0   N/A  N/A     22740    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     22944    C+G   ...ejd91yc\\AdobeNotificationClient.exe      N/A      |\n",
      "|    0   N/A  N/A     23016    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe      N/A      |\n",
      "|    0   N/A  N/A     23124    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     24584    C+G   ...21.0_x64__8wekyb3d8bbwe\\GameBar.exe      N/A      |\n",
      "|    0   N/A  N/A     25184    C+G   ...Programs\\Python\\Python39\\python.exe      N/A      |\n",
      "|    0   N/A  N/A     25308    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     31704    C+G   ...Programs\\Python\\Python39\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en este caso tenemos asignada una P100, ¡no está mal! A continuación, podemos importar todos los paquetes necesarios para ejecutar el modelo propuesto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ya podemos descargar las imágenes de conjunto de datos MNIST de dígitos escritos a mano, que serán las imágenes que consideremos reales para nuestro ejemplo. Podemos hacerlo directamente desde `keras.datasets` y preparar las imágenes para ser usadas por las redes con el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso solo nos interesan las imágenes y, por tanto, no descargamos ni las *labels* ni los datos de prueba (usaremos `_` para indicar que no necesitamos estos datos y que pueden ser desechables).\n",
    "\n",
    "Podemos ver en el código que estas imágenes se han normalizado en el rango [-1, 1] para poder usar como función de activación en la capa final del Generador la funcion `tanh`, como veremos a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = (train_images - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barajamos y preparamos los datos en lotes con el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.2. Creación de los modelos\n",
    "\n",
    "A continuación, ya podemos pasar a crear las redes neuronales que actuarán de Generador y Discriminador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.2.2.1. Generador\n",
    "\n",
    "Siguiendo el esquema que habíamos descrito, el Generador recibe como entrada ruido, que puede obtener por ejemplo con `tf.random.normal`. De este ruido debe crear una imagen de 28 x 28 píxeles.\n",
    "\n",
    "El generador que obtiene una imagen de estas características a partir del vector de ruido que hemos indicado podría ser como el programado en el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12544)             1254400   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 128)      819328    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 14, 14, 128)      512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 14, 14, 64)       204864    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        1601      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,280,961\n",
      "Trainable params: 2,280,577\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Reshape, Conv2DTranspose, BatchNormalization, LeakyReLU\n",
    "\n",
    "def make_generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "\n",
    "    model.add(Reshape((7, 7, 256)))\n",
    "\n",
    "    model.add(Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    model.add(Conv2DTranspose(64, (5, 5), strides=(1, 1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', activation='tanh'))\n",
    "\n",
    "    return model\n",
    "\n",
    "generator = make_generator_model()\n",
    "\n",
    "print(generator.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25d4e7ca250>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise_dim = 100\n",
    "noise = tf.random.normal([1, noise_dim])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.2.2.2. Discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 14, 14, 32)        832       \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 7, 7, 64)          51264     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 7, 7, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 128)         204928    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 4, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 259,841\n",
      "Trainable params: 259,457\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, LeakyReLU, Conv2D\n",
    "\n",
    "def make_discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "discriminator = make_discriminator_model()\n",
    "print(discriminator.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.49979058]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "      \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "grid_size_x= 10\n",
    "grid_size_y= 10\n",
    "seed = tf.random.normal([grid_size_x*grid_size_y , noise_dim])\n",
    "\n",
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    \n",
    "    print ('Processing epoch {}'.format(epoch + 1))\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    generate_images(generator,seed)\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time() - start))\n",
    "\n",
    "  generate_images(generator, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input):\n",
    "  \n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(grid_size_x,grid_size_y))\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(grid_size_x, grid_size_y, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')            \n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Javie\\Documents\\Proyectos\\Python-Deep-Learning\\.venv\\lib\\site-packages\\keras\\backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2000\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_batch \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m---> 14\u001b[0m   \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m generate_images(generator,seed)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime for epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sec\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start))\n",
      "File \u001b[1;32mc:\\Users\\Javie\\Documents\\Proyectos\\Python-Deep-Learning\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Javie\\Documents\\Proyectos\\Python-Deep-Learning\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Javie\\Documents\\Proyectos\\Python-Deep-Learning\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Javie\\Documents\\Proyectos\\Python-Deep-Learning\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Javie\\Documents\\Proyectos\\Python-Deep-Learning\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Javie\\Documents\\Proyectos\\Python-Deep-Learning\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Javie\\Documents\\Proyectos\\Python-Deep-Learning\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 2000\n",
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.3. Funciones de pérdida y optimizadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.3. Enrutamiento de la API de bajo nivel de TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.1. API de bajo nivel de TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.2. Algoritmo de aprendizaje a bajo nivel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.3. Entrenamiento de las redes GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.4. Mejora del rendimiento computacional con decoradores de funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.5. Evaluación de los resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
